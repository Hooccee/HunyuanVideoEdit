{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1\n",
      "Video ID: ['aurora']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['green and blue aurora paints the night sky over mountain silhouettes']\n",
      "Target prompt: ['red and yellow aurora paints the night sky over mountain silhouettes']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['aurora']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['green and blue aurora paints the night sky over mountain silhouettes']\n",
      "Target prompt: ['white and pure cloud paints the night sky over mountain silhouettes']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['aurora']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['green and blue aurora paints the night sky over mountain silhouettes']\n",
      "Target prompt: ['green and blue aurora paints the night sky over mountain silhouettes, van gogh starry night style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['beam']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['symmetric neon light tunnel with blue and purple hues']\n",
      "Target prompt: ['symmetric neon light tunnel with green and yellow hues']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['beam']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['symmetric neon light tunnel with blue and purple hues']\n",
      "Target prompt: ['symmetric neon light tunnel with blue and purple hues, ukiyo-e style painting']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['beam']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['symmetric neon light tunnel with blue and purple hues']\n",
      "Target prompt: ['symmetric neon light tunnel with green and yellow hues, makoto shinkai style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['blackswan']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['black swan is gracefully swimming in a pond with lush greenery in the background']\n",
      "Target prompt: ['pink flamingo is gracefully swimming in a pond with lush greenery in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['blackswan']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['black swan is gracefully swimming in a pond with lush greenery in the background']\n",
      "Target prompt: ['black swan is gracefully swimming in a pond with lush greenery in the background, children drawing']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['blackswan']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['black swan is gracefully swimming in a pond with lush greenery in the background']\n",
      "Target prompt: ['white egret is gracefully swimming in a pond with cherry-blossom trees in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['blue-texture']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['green balls float on blue water']\n",
      "Target prompt: ['orange balls float on blue water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['blue-texture']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['green balls float on blue water']\n",
      "Target prompt: ['green balls float on pink water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['blue-texture']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['green balls float on blue water']\n",
      "Target prompt: ['red cubes float on purple water, cartoon photo']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['boat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white fishing boat sails on blue waters surrounded by small villages']\n",
      "Target prompt: ['a red sailing boat sails on blue waters surrounded by small villages']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['boat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white fishing boat sails on blue waters surrounded by small villages']\n",
      "Target prompt: ['a white fishing boat sails on green waters surrounded by small villages']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['boat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white fishing boat sails on blue waters surrounded by small villages']\n",
      "Target prompt: ['a white fishing boat sails on blue waters surrounded by small villages, picasso artwork']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['boxing-fisheye']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['two boxers sparring in an outdoor ring during the evening with a coach supervising and city buildings and trees in the background']\n",
      "Target prompt: ['two spider-men sparring in an outdoor ring during the evening with a coach supervising and city buildings and trees in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['boxing-fisheye']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['two boxers sparring in an outdoor ring during the evening with a coach supervising and city buildings and trees in the background']\n",
      "Target prompt: ['two boxers sparring in an outdoor ring during the evening with a coach supervising and colorful corals and fish in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['boxing-fisheye']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['two boxers sparring in an outdoor ring during the evening with a coach supervising and city buildings and trees in the background']\n",
      "Target prompt: ['two ninjas sparring in an outdoor ring during the evening with a coach supervising and city buildings and trees in the background, comic style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['bus']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['aerial view of a white and blue bus driving down a city street']\n",
      "Target prompt: ['aerial view of a green and yellow taxi driving down a city street']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['bus']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['aerial view of a white and blue bus driving down a city street']\n",
      "Target prompt: ['aerial view of a white and blue bus driving down a forest road']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['bus']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['aerial view of a white and blue bus driving down a city street']\n",
      "Target prompt: ['aerial view of a white and blue bus driving down a city street, black and white sketch']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['butterfly']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a black and yellow butterfly flutters over a plant in a field eventually alighting on a yellow flower']\n",
      "Target prompt: ['a black and yellow butterfly flutters over a plant in a field eventually alighting on a yellow flower, in 8-bit pixel art style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['butterfly']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a black and yellow butterfly flutters over a plant in a field eventually alighting on a yellow flower']\n",
      "Target prompt: ['a black and yellow butterfly flutters over a plant in a field eventually alighting on a red flower']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['butterfly']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a black and yellow butterfly flutters over a plant in a field eventually alighting on a yellow flower']\n",
      "Target prompt: ['a black and yellow butterfly flutters over a plant in a field eventually alighting on a yellow flower, in a watercolor style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-shadow']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a car navigates city streets transitioning from shadow to sunlight amidst white buildings']\n",
      "Target prompt: ['a car navigates city streets transitioning from shadow to sunlight amidst white buildings, in pixar-style animation.']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-shadow']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a car navigates city streets transitioning from shadow to sunlight amidst white buildings']\n",
      "Target prompt: ['a car navigates snowy streets transitioning from shadow to sunlight amidst white buildings']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-shadow']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a car navigates city streets transitioning from shadow to sunlight amidst white buildings']\n",
      "Target prompt: ['a car navigates city streets transitioning from shadow to sunlight amidst green trees']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-swamp']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white car drives through a puddle of water in the wild']\n",
      "Target prompt: ['a orange boat drives through a puddle of water in the wild']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-swamp']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white car drives through a puddle of water in the wild']\n",
      "Target prompt: ['a white car drives through a puddle of lava in the wild']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-swamp']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white car drives through a puddle of water in the wild']\n",
      "Target prompt: ['a white car drives through a puddle of water in sunset beach']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-turn']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a grey car navigates a curvy road surrounded by green grass trees and mountains during the day']\n",
      "Target prompt: ['a red sports-car navigates a curvy road surrounded by green grass trees and mountains during the day']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-turn']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a grey car navigates a curvy road surrounded by green grass trees and mountains during the day']\n",
      "Target prompt: ['a grey car navigates a curvy road surrounded by snowy landscapes trees and mountains during the day']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['car-turn']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a grey car navigates a curvy road surrounded by green grass trees and mountains during the day']\n",
      "Target prompt: ['a grey car navigates a curvy road surrounded by green grass trees and mountains during the day, in an animated cartoon style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a cat perches atop a wooden fence against blue sky']\n",
      "Target prompt: ['a cat perches atop a wooden fence under the water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a cat perches atop a wooden fence against blue sky']\n",
      "Target prompt: ['a cat perches atop a wooden fence against blue sky, in pokenmon animation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a cat perches atop a wooden fence against blue sky']\n",
      "Target prompt: ['a cogi perches atop a wooden fence against green forest']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cloud']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a large white cloud hovers over a hill']\n",
      "Target prompt: ['a large red cloud hovers over a hill']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cloud']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a large white cloud hovers over a hill']\n",
      "Target prompt: ['a large white cloud hovers over a hill, painted in expressionism style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cloud']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a large white cloud hovers over a hill']\n",
      "Target prompt: [\"a large rainbow-colored cloud hovers over a hill, in van gogh's starry night style\"]\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['count']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['digital number 10 displayed on a clock against a blue screen']\n",
      "Target prompt: ['digital number 10 displayed on a clock against a orange screen']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['count']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['digital number 10 displayed on a clock against a blue screen']\n",
      "Target prompt: ['digital number 10 displayed on a clock against a blue screen, oil painting style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['count']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['digital number 10 displayed on a clock against a blue screen']\n",
      "Target prompt: ['calligraphy number 10 displayed on a clock against a blue screen']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cows']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a brown and white cow is walking through a field of grass and mud']\n",
      "Target prompt: ['a black and white panda is walking through a field of grass and mud']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cows']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a brown and white cow is walking through a field of grass and mud']\n",
      "Target prompt: ['a brown and white cow is walking through a field of wheat and flowers']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cows']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a brown and white cow is walking through a field of grass and mud']\n",
      "Target prompt: ['a black and white zebra is walking through a field of mountains and lake']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cross-city']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['an urban street flanked by buildings with the sun casting long shadows']\n",
      "Target prompt: ['an urban street flanked by buildings with the moon casting long shadows']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cross-city']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['an urban street flanked by buildings with the sun casting long shadows']\n",
      "Target prompt: ['an urban street flanked by buildings with the sun casting long shadows, animation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['cross-city']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['an urban street flanked by buildings with the sun casting long shadows']\n",
      "Target prompt: ['an urban street flanked by ice-cream with the sun casting long shadows']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['crossing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['pedestrians cross the street at a busy crosswalk in front of a building']\n",
      "Target prompt: ['spiderman cross the street at a busy crosswalk in front of a building']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['crossing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['pedestrians cross the street at a busy crosswalk in front of a building']\n",
      "Target prompt: ['pedestrians cross the street at a busy crosswalk in front of a building, animation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['crossing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['pedestrians cross the street at a busy crosswalk in front of a building']\n",
      "Target prompt: ['pedestrians cross the street at a busy crosswalk in front of a forest']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['dance-twirl']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a woman in a blue dress captivates a street crowd with her mesmerizing dance moves']\n",
      "Target prompt: ['a woman in a white t-shirt captivates a street crowd with her mesmerizing dance moves']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['dance-twirl']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a woman in a blue dress captivates a street crowd with her mesmerizing dance moves']\n",
      "Target prompt: ['a woman in a blue dress captivates a street crowd with her mesmerizing dance moves, studio ghibli style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['dance-twirl']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a woman in a blue dress captivates a street crowd with her mesmerizing dance moves']\n",
      "Target prompt: ['a woman in a red dress captivates a street crowd with her mesmerizing dance moves, vibrant film style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['dog-agility']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a dog is navigating poles in an obstacle course weaving through poles against a gym backdrop with green grass']\n",
      "Target prompt: ['a dog is navigating poles in an obstacle course weaving through poles against a beach backdrop with palm trees']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['dog-agility']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a dog is navigating poles in an obstacle course weaving through poles against a gym backdrop with green grass']\n",
      "Target prompt: ['a dog is navigating poles in an obstacle course weaving through poles against a gym backdrop with green grass, claymation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['dog-agility']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a dog is navigating poles in an obstacle course weaving through poles against a gym backdrop with green grass']\n",
      "Target prompt: ['a toy-car is navigating poles in an obstacle course weaving through poles against a gym backdrop with green grass']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['flamingo']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['flamingos are drinking water by a tree surrounded by blue water and green shores']\n",
      "Target prompt: ['flamingos are drinking water by a tree surrounded by sandy beach and turquoise water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['flamingo']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['flamingos are drinking water by a tree surrounded by blue water and green shores']\n",
      "Target prompt: ['flamingos are drinking water by a tree surrounded by blue water and green shores, in a cyber punk sci-fi style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['flamingo']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['flamingos are drinking water by a tree surrounded by blue water and green shores']\n",
      "Target prompt: ['giraffes are drinking water by a tree surrounded by blue water and green shores, in a disney animation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['helicopter']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white and blue helicopter is lifting off from the green rooftop of a building near the ocean']\n",
      "Target prompt: ['a red and yellow balloon is lifting off from the green rooftop of a building near the ocean']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['helicopter']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white and blue helicopter is lifting off from the green rooftop of a building near the ocean']\n",
      "Target prompt: ['a white and blue helicopter is lifting off from the snowy rooftop of a building near the ocean']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['helicopter']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white and blue helicopter is lifting off from the green rooftop of a building near the ocean']\n",
      "Target prompt: ['a white and blue helicopter is lifting off from the green rooftop of a building near the ocean, in a chibi animation filter']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['hike']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man with a backpack hikes through the dolomites']\n",
      "Target prompt: ['a man with a giant-pencil hikes through the dolomites']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['hike']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man with a backpack hikes through the dolomites']\n",
      "Target prompt: ['a superman with a backpack hikes through the desert']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['hike']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man with a backpack hikes through the dolomites']\n",
      "Target prompt: ['a man with a backpack hikes through the dolomites, pixel art']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['hockey']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man on roller blades is playing inline hockey in an outdoor rink']\n",
      "Target prompt: ['a man on roller blades is playing inline hockey in an underwater rink']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['hockey']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man on roller blades is playing inline hockey in an outdoor rink']\n",
      "Target prompt: ['a man on roller blades is playing inline hockey in an outdoor rink, claymation animation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['hockey']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man on roller blades is playing inline hockey in an outdoor rink']\n",
      "Target prompt: ['a panda on roller blades is playing inline hockey in an outdoor rink']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['horsejump-high']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rider on horse navigates an obstacle course jumping hurdles']\n",
      "Target prompt: ['a rider on horse navigates an obstacle course jumping hurdles, in oil painting style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['horsejump-high']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rider on horse navigates an obstacle course jumping hurdles']\n",
      "Target prompt: ['a rider on horse navigates an obstacle course jumping hurdles, in a comic book style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['horsejump-high']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rider on horse navigates an obstacle course jumping hurdles']\n",
      "Target prompt: ['a rider on llama navigates an obstacle course jumping hurdles']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['ink']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a drop of orange ink falling onto a white water']\n",
      "Target prompt: ['a box of lemon fruits falling onto a white water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['ink']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a drop of orange ink falling onto a white water']\n",
      "Target prompt: ['a drop of orange ink falling onto a green water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['ink']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a drop of orange ink falling onto a white water']\n",
      "Target prompt: ['a drop of orange ink falling onto a white water, black-white chinese watercolor style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['jellyfish']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['blue ocean with mesmerizing footage of striped jellyfish']\n",
      "Target prompt: ['coral reef with mesmerizing footage of striped jellyfish, illuminated by neon lights']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['jellyfish']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['blue ocean with mesmerizing footage of striped jellyfish']\n",
      "Target prompt: ['red ocean with mesmerizing footage of striped jellyfish']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['jellyfish']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['blue ocean with mesmerizing footage of striped jellyfish']\n",
      "Target prompt: ['blue ocean with mesmerizing footage of striped jellyfish, van gogh starry night style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['kite-surf']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a person kiteboarding on turquoise waters with a coastal cityscape and mountain in the background']\n",
      "Target prompt: ['a superman running on turquoise waters with a coastal cityscape and mountain in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['kite-surf']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a person kiteboarding on turquoise waters with a coastal cityscape and mountain in the background']\n",
      "Target prompt: ['a person kiteboarding on lava lake with a coastal cityscape and mountain in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['kite-surf']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a person kiteboarding on turquoise waters with a coastal cityscape and mountain in the background']\n",
      "Target prompt: ['a person kiteboarding on turquoise waters with a coastal cityscape and mountain in the background, pixar animation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['lab-coat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['three girls in lab coats are standing atop a grassy field as the camera closes in']\n",
      "Target prompt: ['three astronauts in spaceman costume are standing atop a grassy field as the camera closes in, stylized in an oil painting']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['lab-coat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['three girls in lab coats are standing atop a grassy field as the camera closes in']\n",
      "Target prompt: ['three cats in lab coats are standing atop a grassy field as the camera closes in']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['lab-coat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['three girls in lab coats are standing atop a grassy field as the camera closes in']\n",
      "Target prompt: ['three girls in lab coats are standing atop a grassy field as the camera closes in, paper cutout animation style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['landing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white passenger jet lands on a grey autumn runway']\n",
      "Target prompt: ['a white passenger jet lands on a grey winter runway']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['landing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white passenger jet lands on a grey autumn runway']\n",
      "Target prompt: ['a white passenger jet lands on a sunny beach runway']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['landing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a white passenger jet lands on a grey autumn runway']\n",
      "Target prompt: ['a red passenger jet lands on a sunny tropical runway']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['makeup']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a young woman with a towel wrapped around her head applying makeup with a brush']\n",
      "Target prompt: ['a bearded man with a pumpkin wrapped around his head applying makeup with a brush']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['makeup']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a young woman with a towel wrapped around her head applying makeup with a brush']\n",
      "Target prompt: ['a young woman with a towel wrapped around her head applying makeup with a brush, in an oil painting style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['makeup']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a young woman with a towel wrapped around her head applying makeup with a brush']\n",
      "Target prompt: ['a santa claus with a hat wrapped around his head applying makeup with a brush, in pixar cartoon style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['man-skiing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a snowboarder in a yellow jacket carves down a snowy mountain slope against a blue sky']\n",
      "Target prompt: ['a snowboarder in a yellow jacket carves down a green prairie slope against a blue sky']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['man-skiing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a snowboarder in a yellow jacket carves down a snowy mountain slope against a blue sky']\n",
      "Target prompt: ['a snowboarder in a yellow jacket carves down a snowy mountain slope against a pink sky']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['man-skiing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a snowboarder in a yellow jacket carves down a snowy mountain slope against a blue sky']\n",
      "Target prompt: ['a snowboarder in a yellow jacket carves down a desert mountain slope against a vibrant sunset']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['man-surfing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man surfs atop waves on a surfboard in the ocean']\n",
      "Target prompt: ['a man surfs atop waves on a inflatable-duck in the ocean']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['man-surfing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man surfs atop waves on a surfboard in the ocean']\n",
      "Target prompt: ['a man surfs atop waves on a surfboard in the ocean, in a retro film grain effect']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['man-surfing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man surfs atop waves on a surfboard in the ocean']\n",
      "Target prompt: ['a emu surfs atop waves on a surfboard in the ocean, ocean with a tropical paradise background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['moonwalk']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a white shirt and black pants wearing gray sneakers performing the moonwalk dance move on a wooden floor']\n",
      "Target prompt: ['a clown in a white shirt and red pants wearing gray sneakers performing the moonwalk dance move on a wooden floor']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['moonwalk']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a white shirt and black pants wearing gray sneakers performing the moonwalk dance move on a wooden floor']\n",
      "Target prompt: ['a man in a white shirt and black pants wearing gray sneakers performing the moonwalk dance move on a sunny outdoor']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['moonwalk']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a white shirt and black pants wearing gray sneakers performing the moonwalk dance move on a wooden floor']\n",
      "Target prompt: ['a man in a white shirt and black pants wearing gray sneakers performing the moonwalk dance move on a wooden floor, in picasso artstyle']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['motorbike']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['an orange motorcycle riding on a road with a forest and mountains in the background']\n",
      "Target prompt: ['an orange motorcycle riding on a road with a forest and mountains in the background, in surealist style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['motorbike']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['an orange motorcycle riding on a road with a forest and mountains in the background']\n",
      "Target prompt: ['a brown wolf runing on a road with a desert and pyramids in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['motorbike']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['an orange motorcycle riding on a road with a forest and mountains in the background']\n",
      "Target prompt: ['a pink car driving on a road with a forest and mountains in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['overlook-the-ocean']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['top-down view of waves crashing against a rocky shore with turquoise waters']\n",
      "Target prompt: ['top-down view of seagulls flying against a rocky shore with turquoise waters']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['overlook-the-ocean']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['top-down view of waves crashing against a rocky shore with turquoise waters']\n",
      "Target prompt: ['top-down view of waves crashing against a sandy shore with turquoise waters']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['overlook-the-ocean']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['top-down view of waves crashing against a rocky shore with turquoise waters']\n",
      "Target prompt: ['top-down view of waves crashing against a rocky shore with turquoise waters, black and white stylization']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['parkour']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man performing parkour jumping over barriers in an urban setting with modern buildings in the background']\n",
      "Target prompt: ['a man performing parkour jumping over barriers in an urban setting with metal buildings in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['parkour']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man performing parkour jumping over barriers in an urban setting with modern buildings in the background']\n",
      "Target prompt: ['a man performing parkour jumping over barriers in an urban setting with modern buildings in the background, disney cartoon style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['parkour']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man performing parkour jumping over barriers in an urban setting with modern buildings in the background']\n",
      "Target prompt: ['a mickey-mouse performing parkour jumping over barriers in an urban setting with modern buildings in the background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['parrot-eat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['feeding a yellow parrot on a hand in the countryside']\n",
      "Target prompt: ['feeding a brown squirrel on a hand in the countryside']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['parrot-eat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['feeding a yellow parrot on a hand in the countryside']\n",
      "Target prompt: ['feeding a yellow parrot on a hand in snowy mountains']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['parrot-eat']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['feeding a yellow parrot on a hand in the countryside']\n",
      "Target prompt: ['feeding a yellow parrot on a hand in the countryside, sketch styled drawing']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['pyramid']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['exploring the vastness of the pyramids of giza rising in the desert']\n",
      "Target prompt: ['exploring the vastness of the pyramids of giza rising in the rainforest']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['pyramid']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['exploring the vastness of the pyramids of giza rising in the desert']\n",
      "Target prompt: ['exploring the vastness of the pyramids of giza rising in the cityscape']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['pyramid']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['exploring the vastness of the pyramids of giza rising in the desert']\n",
      "Target prompt: ['exploring the vastness of the pyramids of giza rising in the desert, reminiscent of old documentaries']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['rabbit-watermelon']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rabbit is eating watermelon on table against white wall']\n",
      "Target prompt: ['a puppy is eating watermelon on table against white wall']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['rabbit-watermelon']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rabbit is eating watermelon on table against white wall']\n",
      "Target prompt: ['a rabbit is eating pizza on table against white wall']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['rabbit-watermelon']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rabbit is eating watermelon on table against white wall']\n",
      "Target prompt: ['a tiger is sitting quietly on table against beach background']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['rollerblade']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rollerblader performing a jumping trick in front of a graffiti-covered wall']\n",
      "Target prompt: ['a rollerblader performing a jumping trick in front of a graffiti-covered wall, cartoon drawing style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['rollerblade']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rollerblader performing a jumping trick in front of a graffiti-covered wall']\n",
      "Target prompt: ['a rollerblader performing a jumping trick in front of a mountain landscape']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['rollerblade']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a rollerblader performing a jumping trick in front of a graffiti-covered wall']\n",
      "Target prompt: ['a monkey performing a jumping trick in front of a graffiti-covered wall, in expressionism style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['suitguy']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a black suit stands indoors as the camera approaches in dim light']\n",
      "Target prompt: ['a man in a superhero costume stands indoors as the camera approaches in dim light']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['suitguy']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a black suit stands indoors as the camera approaches in dim light']\n",
      "Target prompt: ['a man in a black suit stands indoors as the camera approaches in dim light, in sesame street style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['suitguy']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a black suit stands indoors as the camera approaches in dim light']\n",
      "Target prompt: ['a man in an astronaut suit stands indoors as the camera approaches in dim light, in disney style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['surf']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['windsurfing in the mediterranean sea with a green sailboat']\n",
      "Target prompt: ['windsurfing in the mediterranean sea with a pink sailboat']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['surf']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['windsurfing in the mediterranean sea with a green sailboat']\n",
      "Target prompt: ['windsurfing in the arctic ocean with a green sailboat']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['surf']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['windsurfing in the mediterranean sea with a green sailboat']\n",
      "Target prompt: ['windsurfing in the mediterranean sea with a inflatable flamingo']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['swing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a girl in a white shirt and jeans is swinging in the park']\n",
      "Target prompt: ['a girl in a white shirt and jeans is swinging in snowy park']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['swing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a girl in a white shirt and jeans is swinging in the park']\n",
      "Target prompt: ['a girl in a white shirt and jeans is swinging in bustling cityscape']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['swing']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a girl in a white shirt and jeans is swinging in the park']\n",
      "Target prompt: ['a girl in a white shirt and jeans is swinging in the park, comic book art style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['tennis']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in white plays tennis on a clay court hitting the ball with a racket']\n",
      "Target prompt: ['a man in white plays tennis on a grass court hitting the ball with a racket']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['tennis']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in white plays tennis on a clay court hitting the ball with a racket']\n",
      "Target prompt: ['a man in white plays tennis on a clay court hitting the ball with a racket, in studio ghibli style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['tennis']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in white plays tennis on a clay court hitting the ball with a racket']\n",
      "Target prompt: ['a woman in red plays tennis on a clay court hitting the ball with a racket']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['toy-rocket']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a toy rocket launches from the grass near a tree propelled by water']\n",
      "Target prompt: ['a toy rocket launches from the sand near a palm-tree propelled by water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['toy-rocket']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a toy rocket launches from the grass near a tree propelled by water']\n",
      "Target prompt: ['a toy rocket launches from the grass near a tree propelled by pigments']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['toy-rocket']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a toy rocket launches from the grass near a tree propelled by water']\n",
      "Target prompt: ['a toy rocket launches from the grass near a tree propelled by flames']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['two-swan']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['two swans grace a tranquil dawn standing in reflecting water']\n",
      "Target prompt: ['two swans grace a tranquil dawn standing in lush forest']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['two-swan']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['two swans grace a tranquil dawn standing in reflecting water']\n",
      "Target prompt: ['two swans grace a tranquil dawn standing in reflecting water, dawn in a chinese watercolor painting style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['two-swan']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['two swans grace a tranquil dawn standing in reflecting water']\n",
      "Target prompt: ['two giraffes grace a tranquil dawn standing in reflecting water']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['upside-down']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a bald man in sunglasses rides a yellow fast-paced roller coaster sporting a blue shirt']\n",
      "Target prompt: ['a young man without accessories rides a yellow fast-paced roller coaster sporting a blue shirt']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['upside-down']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a bald man in sunglasses rides a yellow fast-paced roller coaster sporting a blue shirt']\n",
      "Target prompt: ['a bald man in sunglasses rides a yellow fast-paced roller coaster sporting a blue shirt, minecraft world style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['upside-down']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a bald man in sunglasses rides a yellow fast-paced roller coaster sporting a blue shirt']\n",
      "Target prompt: ['a cute cat in sunglasses rides a yellow fast-paced roller coaster sporting a blue shirt']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['volcanic-eruption']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['aerial view captures lava erupting pouring from iceland crater']\n",
      "Target prompt: ['aerial view captures sprint erupting pouring from iceland crater']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['volcanic-eruption']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['aerial view captures lava erupting pouring from iceland crater']\n",
      "Target prompt: ['aerial view captures lava erupting pouring from iceland crater, picasso oil painting']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['volcanic-eruption']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['aerial view captures lava erupting pouring from iceland crater']\n",
      "Target prompt: ['aerial view captures lava erupting pouring from birthday cake']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['walking']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a blue suit is walking down the street and taking a selfie']\n",
      "Target prompt: ['a man in a blue suit is walking down the village and taking a selfie']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['walking']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a blue suit is walking down the street and taking a selfie']\n",
      "Target prompt: ['a man in a blue suit is walking down the street and taking a selfie, an abstract painting style']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['walking']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a man in a blue suit is walking down the street and taking a selfie']\n",
      "Target prompt: ['a woman in a green dress is walking down the street and taking a selfie']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['woman-dog']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a woman is taking a selfie with a dog with a cell phone amidst yellow weeds']\n",
      "Target prompt: ['a woman is taking a selfie with a capybara with a cell phone amidst yellow weeds']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['woman-dog']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a woman is taking a selfie with a dog with a cell phone amidst yellow weeds']\n",
      "Target prompt: ['a woman is taking a selfie with a dog with a cell phone amidst yellow sunflowers']\n",
      "---\n",
      "Batch size: 1\n",
      "Video ID: ['woman-dog']\n",
      "Video shape: torch.Size([1, 24, 512, 512, 3])\n",
      "Source prompt: ['a woman is taking a selfie with a dog with a cell phone amidst yellow weeds']\n",
      "Target prompt: ['a farmer is taking a selfie with a cow with a cell phone amidst green meadows']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from regex import F\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_video\n",
    "\n",
    "class V2VBenchDataset(Dataset):\n",
    "    def __init__(self, config_path, videos_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            config_path (str): Path to config.yaml file\n",
    "            videos_dir (str): Directory containing video files\n",
    "        \"\"\"\n",
    "        self.videos_dir = videos_dir\n",
    "        \n",
    "        # Load config file\n",
    "        with open(config_path, 'r') as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        \n",
    "        # Flatten the data structure\n",
    "        self.samples = []\n",
    "        for video_data in self.config['data']:\n",
    "            video_id = video_data['video_id']\n",
    "            source_prompt = video_data['prompt']\n",
    "            video_path = os.path.join(self.videos_dir, f\"{video_id}.mp4\")\n",
    "            \n",
    "            for edit in video_data['edit']:\n",
    "                target_prompt = edit['prompt']\n",
    "                self.samples.append({\n",
    "                    'video_path': video_path,\n",
    "                    'video_id': video_id,\n",
    "                    'source_prompt': source_prompt,\n",
    "                    'target_prompt': target_prompt,\n",
    "                    'src_words': edit.get('src_words', ''),\n",
    "                    'tgt_words': edit.get('tgt_words', ''),\n",
    "                    'edit_type': edit.get('type', '')\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load video (frames, audio, info)\n",
    "        # Note: You may need to adjust this based on your video format and needs\n",
    "        video, _, info = read_video(sample['video_path'], pts_unit='sec')\n",
    "        \n",
    "        # Convert video to float and normalize to [0, 1]\n",
    "        video = video.float() / 255.0\n",
    "        \n",
    "        return {\n",
    "            'video': video,\n",
    "            'video_id': sample['video_id'],\n",
    "            'source_prompt': sample['source_prompt'],\n",
    "            'target_prompt': sample['target_prompt'],\n",
    "            'src_words': sample['src_words'],\n",
    "            'tgt_words': sample['tgt_words'],\n",
    "            'edit_type': sample['edit_type']\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    config_path = \"/data/chx/V2VBench/config.yaml\"\n",
    "    videos_dir = \"/data/chx/V2VBench/videos\"\n",
    "    \n",
    "    dataset = V2VBenchDataset(config_path, videos_dir)\n",
    "    \n",
    "    # Create a DataLoader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Iterate through the dataset\n",
    "    for batch in dataloader:\n",
    "        print(f\"Batch size: {len(batch['video'])}\")\n",
    "        print(f\"Video ID: {batch['video_id']}\")\n",
    "        print(f\"Video shape: {batch['video'].shape}\")\n",
    "        print(f\"Source prompt: {batch['source_prompt']}\")\n",
    "        print(f\"Target prompt: {batch['target_prompt']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chx/anaconda3/envs/HunyuanVideo-std/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect you are not use the latest yunchang. Please install yunchang>=0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: edit_video.py [-h] [--model {HYVideo-T/2,HYVideo-T/2-cfgdistill}]\n",
      "                     [--latent-channels LATENT_CHANNELS]\n",
      "                     [--precision {fp16,bf16,fp32}] [--rope-theta ROPE_THETA]\n",
      "                     [--vae {884-16c-hy}] [--vae-precision {fp16,bf16,fp32}]\n",
      "                     [--vae-tiling] [--text-encoder {clipL,llm}]\n",
      "                     [--text-encoder-precision {fp16,bf16,fp32}]\n",
      "                     [--text-states-dim TEXT_STATES_DIM] [--text-len TEXT_LEN]\n",
      "                     [--tokenizer {clipL,llm}]\n",
      "                     [--prompt-template {dit-llm-encode,dit-llm-encode-video}]\n",
      "                     [--prompt-template-video {dit-llm-encode,dit-llm-encode-video}]\n",
      "                     [--hidden-state-skip-layer HIDDEN_STATE_SKIP_LAYER]\n",
      "                     [--apply-final-norm] [--text-encoder-2 {clipL,llm}]\n",
      "                     [--text-encoder-precision-2 {fp16,bf16,fp32}]\n",
      "                     [--text-states-dim-2 TEXT_STATES_DIM_2]\n",
      "                     [--tokenizer-2 {clipL,llm}] [--text-len-2 TEXT_LEN_2]\n",
      "                     [--denoise-type DENOISE_TYPE] [--flow-shift FLOW_SHIFT]\n",
      "                     [--flow-reverse] [--flow-solver FLOW_SOLVER]\n",
      "                     [--use-linear-quadratic-schedule]\n",
      "                     [--linear-schedule-end LINEAR_SCHEDULE_END]\n",
      "                     [--model-base MODEL_BASE] [--dit-weight DIT_WEIGHT]\n",
      "                     [--model-resolution {540p,720p}] [--load-key LOAD_KEY]\n",
      "                     [--use-cpu-offload] [--batch-size BATCH_SIZE]\n",
      "                     [--infer-steps INFER_STEPS] [--disable-autocast]\n",
      "                     [--save-path SAVE_PATH]\n",
      "                     [--save-path-suffix SAVE_PATH_SUFFIX]\n",
      "                     [--name-suffix NAME_SUFFIX] [--num-videos NUM_VIDEOS]\n",
      "                     [--video-size VIDEO_SIZE [VIDEO_SIZE ...]]\n",
      "                     [--video-length VIDEO_LENGTH]\n",
      "                     [--seed-type {file,random,fixed,auto}] [--seed SEED]\n",
      "                     [--neg-prompt NEG_PROMPT] [--cfg-scale CFG_SCALE]\n",
      "                     [--embedded-cfg-scale EMBEDDED_CFG_SCALE] [--use-fp8]\n",
      "                     [--reproduce] [--ulysses-degree ULYSSES_DEGREE]\n",
      "                     [--ring-degree RING_DEGREE]\n",
      "                     [--inverse-video-path INVERSE_VIDEO_PATH]\n",
      "                     [--prompt PROMPT] [--target-prompt TARGET_PROMPT]\n",
      "                     [--inject INJECT] [--feature-path FEATURE_PATH]\n",
      "                     [--dataset {V2VBench}]\n",
      "edit_video.py: error: Cannot specify both --dataset and edit parameters (--inverse-video-path/--prompt/--target-prompt)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run edit_video.py \\\n",
    "    --dit-weight \"/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt\" \\\n",
    "    --video-size 512 512 \\\n",
    "    --video-length 25 \\\n",
    "    --infer-steps 30 \\\n",
    "    --prompt \"a grey car navigates a curvy road surrounded by green grass trees and mountains.\" \\\n",
    "    --target-prompt \"a red sports-car navigates a curvy road surrounded by green grass trees and mountains.\" \\\n",
    "    --inject 5 \\\n",
    "    --seed 42 \\\n",
    "    --embedded-cfg-scale 2 \\\n",
    "    --flow-shift 7.0 \\\n",
    "    --flow-reverse \\\n",
    "    --use-cpu-offload \\\n",
    "    --use-fp8 \\\n",
    "    --save-path ./results/rf-solver_2order \\\n",
    "    --inverse-video-path \"/data/chx/V2VBench/videos/car-turn.mp4\" \\\n",
    "    --dataset \"V2VBench\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chx/anaconda3/envs/HunyuanVideo-std/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-04-03 12:39:28.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mGot text-to-video model root path: ckpts\u001b[0m\n",
      "\u001b[32m2025-04-03 12:39:28.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1mBuilding model...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect you are not use the latest yunchang. Please install yunchang>=0.4.0\n",
      "{'apply_final_norm': False,\n",
      " 'batch_size': 1,\n",
      " 'cfg_scale': 1.0,\n",
      " 'denoise_type': 'flow',\n",
      " 'disable_autocast': False,\n",
      " 'dit_weight': '/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt',\n",
      " 'embedded_cfg_scale': 2.0,\n",
      " 'feature_path': 'feature',\n",
      " 'flow_reverse': True,\n",
      " 'flow_shift': 7.0,\n",
      " 'flow_solver': 'euler',\n",
      " 'hidden_state_skip_layer': 2,\n",
      " 'infer_steps': 30,\n",
      " 'inject': 5,\n",
      " 'inverse_video_path': '/data/chx/V2VBench/videos/car-turn.mp4',\n",
      " 'latent_channels': 16,\n",
      " 'linear_schedule_end': 25,\n",
      " 'load_key': 'module',\n",
      " 'model': 'HYVideo-T/2-cfgdistill',\n",
      " 'model_base': 'ckpts',\n",
      " 'model_resolution': '540p',\n",
      " 'name_suffix': '',\n",
      " 'neg_prompt': None,\n",
      " 'num_videos': 1,\n",
      " 'precision': 'bf16',\n",
      " 'prompt': 'a grey car navigates a curvy road surrounded by green grass trees '\n",
      "           'and mountains.',\n",
      " 'prompt_template': 'dit-llm-encode',\n",
      " 'prompt_template_video': 'dit-llm-encode-video',\n",
      " 'reproduce': False,\n",
      " 'ring_degree': 1,\n",
      " 'rope_theta': 256,\n",
      " 'save_path': './results/rf-solver_2order',\n",
      " 'save_path_suffix': '',\n",
      " 'seed': 42,\n",
      " 'seed_type': 'auto',\n",
      " 'target_prompt': 'a red sports-car navigates a curvy road surrounded by green '\n",
      "                  'grass trees and mountains.',\n",
      " 'text_encoder': 'llm',\n",
      " 'text_encoder_2': 'clipL',\n",
      " 'text_encoder_precision': 'fp16',\n",
      " 'text_encoder_precision_2': 'fp16',\n",
      " 'text_len': 256,\n",
      " 'text_len_2': 77,\n",
      " 'text_states_dim': 4096,\n",
      " 'text_states_dim_2': 768,\n",
      " 'tokenizer': 'llm',\n",
      " 'tokenizer_2': 'clipL',\n",
      " 'ulysses_degree': 1,\n",
      " 'use_cpu_offload': True,\n",
      " 'use_fp8': True,\n",
      " 'use_linear_quadratic_schedule': False,\n",
      " 'vae': '884-16c-hy',\n",
      " 'vae_precision': 'fp16',\n",
      " 'vae_tiling': True,\n",
      " 'video_length': 25,\n",
      " 'video_size': [512, 512]}\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chx/mySrc/HunyuanVideo/hyvideo/modules/fp8_optimization.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fp8_map = torch.load(fp8_map_path, map_location=lambda storage, loc: storage)\n",
      "\u001b[32m2025-04-03 12:41:45.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mload_state_dict\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mLoading torch model /home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt...\u001b[0m\n",
      "/home/chx/mySrc/HunyuanVideo/hyvideo/inference.py:346: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
      "\u001b[32m2025-04-03 12:43:30.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLoading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-t2v-720p/vae\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chx/mySrc/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(vae_ckpt, map_location=vae.device)\n",
      "\u001b[32m2025-04-03 12:43:38.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mVAE to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-04-03 12:43:38.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "Loading checkpoint shards: 100%|| 4/4 [02:33<00:00, 38.44s/it]\n",
      "\u001b[32m2025-04-03 12:46:18.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-04-03 12:46:18.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "\u001b[32m2025-04-03 12:46:19.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[32m2025-04-03 12:46:25.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-04-03 12:46:25.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable sequential CPU offload.\n",
      "Updated args:\n",
      "{'apply_final_norm': False,\n",
      " 'batch_size': 1,\n",
      " 'cfg_scale': 1.0,\n",
      " 'denoise_type': 'flow',\n",
      " 'disable_autocast': False,\n",
      " 'dit_weight': '/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt',\n",
      " 'embedded_cfg_scale': 2.0,\n",
      " 'feature_path': 'feature',\n",
      " 'flow_reverse': True,\n",
      " 'flow_shift': 7.0,\n",
      " 'flow_solver': 'euler',\n",
      " 'hidden_state_skip_layer': 2,\n",
      " 'infer_steps': 30,\n",
      " 'inject': 5,\n",
      " 'inverse_video_path': '/data/chx/V2VBench/videos/car-turn.mp4',\n",
      " 'latent_channels': 16,\n",
      " 'linear_schedule_end': 25,\n",
      " 'load_key': 'module',\n",
      " 'model': 'HYVideo-T/2-cfgdistill',\n",
      " 'model_base': 'ckpts',\n",
      " 'model_resolution': '540p',\n",
      " 'name_suffix': '',\n",
      " 'neg_prompt': None,\n",
      " 'num_videos': 1,\n",
      " 'precision': 'bf16',\n",
      " 'prompt': 'a grey car navigates a curvy road surrounded by green grass trees '\n",
      "           'and mountains.',\n",
      " 'prompt_template': 'dit-llm-encode',\n",
      " 'prompt_template_video': 'dit-llm-encode-video',\n",
      " 'reproduce': False,\n",
      " 'ring_degree': 1,\n",
      " 'rope_theta': 256,\n",
      " 'save_path': './results/rf-solver_2order',\n",
      " 'save_path_suffix': '',\n",
      " 'seed': 42,\n",
      " 'seed_type': 'auto',\n",
      " 'target_prompt': 'a red sports-car navigates a curvy road surrounded by green '\n",
      "                  'grass trees and mountains.',\n",
      " 'text_encoder': 'llm',\n",
      " 'text_encoder_2': 'clipL',\n",
      " 'text_encoder_precision': 'fp16',\n",
      " 'text_encoder_precision_2': 'fp16',\n",
      " 'text_len': 256,\n",
      " 'text_len_2': 77,\n",
      " 'text_states_dim': 4096,\n",
      " 'text_states_dim_2': 768,\n",
      " 'tokenizer': 'llm',\n",
      " 'tokenizer_2': 'clipL',\n",
      " 'ulysses_degree': 1,\n",
      " 'use_cpu_offload': True,\n",
      " 'use_fp8': True,\n",
      " 'use_linear_quadratic_schedule': False,\n",
      " 'vae': '884-16c-hy',\n",
      " 'vae_precision': 'fp16',\n",
      " 'vae_tiling': True,\n",
      " 'video_length': 25,\n",
      " 'video_size': [512, 512]}\n",
      "FPS of the video: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 12:46:27.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mInput (height, width, video_length) = (512, 512, 25)\u001b[0m\n",
      "\u001b[32m2025-04-03 12:46:27.689\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m665\u001b[0m - \u001b[34m\u001b[1m\n",
      "                        height: 512\n",
      "                         width: 512\n",
      "                  video_length: 25\n",
      "                        prompt: ['a grey car navigates a curvy road surrounded by green grass trees and mountains.']\n",
      "                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']\n",
      "                          seed: 42\n",
      "                   infer_steps: 30\n",
      "         num_videos_per_prompt: 1\n",
      "                guidance_scale: 1.0\n",
      "                      n_tokens: 7168\n",
      "                    flow_shift: 7.0\n",
      "       embedded_guidance_scale: 2.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "sigmas_reverse\n",
      "sigmas: tensor([0.0000, 0.1944, 0.3333, 0.4375, 0.5185, 0.5833, 0.6364, 0.6806, 0.7179,\n",
      "        0.7500, 0.7778, 0.8021, 0.8235, 0.8426, 0.8596, 0.8750, 0.8889, 0.9015,\n",
      "        0.9130, 0.9236, 0.9333, 0.9423, 0.9506, 0.9583, 0.9655, 0.9722, 0.9785,\n",
      "        0.9844, 0.9899, 0.9951, 1.0000])\n",
      "Using inversed latents\n",
      "Step 0: t = 0.0\n",
      "Step 1: t = 194.44444274902344\n",
      "Step 2: t = 333.3333435058594\n",
      "Step 3: t = 437.5000305175781\n",
      "Step 4: t = 518.5184936523438\n",
      "Step 5: t = 583.3333740234375\n",
      "Step 6: t = 636.3637084960938\n",
      "Step 7: t = 680.5556030273438\n",
      "Step 8: t = 717.94873046875\n",
      "Step 9: t = 750.0\n",
      "Step 10: t = 777.77783203125\n",
      "Step 11: t = 802.0833129882812\n",
      "Step 12: t = 823.5294189453125\n",
      "Step 13: t = 842.5925903320312\n",
      "Step 14: t = 859.6491088867188\n",
      "Step 15: t = 875.0\n",
      "Step 16: t = 888.888916015625\n",
      "Step 17: t = 901.51513671875\n",
      "Step 18: t = 913.04345703125\n",
      "Step 19: t = 923.611083984375\n",
      "Step 20: t = 933.333251953125\n",
      "Step 21: t = 942.3078002929688\n",
      "Step 22: t = 950.6172485351562\n",
      "Step 23: t = 958.3333740234375\n",
      "Step 24: t = 965.5172119140625\n",
      "Step 25: t = 972.22216796875\n",
      "Step 26: t = 978.49462890625\n",
      "Step 27: t = 984.375\n",
      "Step 28: t = 989.8989868164062\n",
      "Step 29: t = 995.0980834960938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: t_curr = 0.0, t_prev = 194.44444274902344\n",
      "t:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:03<01:41,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: t_curr = 194.44444274902344, t_prev = 333.3333435058594\n",
      "t:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:06<01:33,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: t_curr = 333.3333435058594, t_prev = 437.5000305175781\n",
      "t:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:09<01:28,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: t_curr = 437.5000305175781, t_prev = 518.5184936523438\n",
      "t:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:13<01:24,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: t_curr = 518.5184936523438, t_prev = 583.3333740234375\n",
      "t:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:16<01:20,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: t_curr = 583.3333740234375, t_prev = 636.3637084960938\n",
      "t:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:19<01:17,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: t_curr = 636.3637084960938, t_prev = 680.5556030273438\n",
      "t:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:22<01:13,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: t_curr = 680.5556030273438, t_prev = 717.94873046875\n",
      "t:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:25<01:10,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: t_curr = 717.94873046875, t_prev = 750.0\n",
      "t:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [00:28<01:06,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: t_curr = 750.0, t_prev = 777.77783203125\n",
      "t:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [00:32<01:03,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: t_curr = 777.77783203125, t_prev = 802.0833129882812\n",
      "t:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [00:35<01:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11: t_curr = 802.0833129882812, t_prev = 823.5294189453125\n",
      "t:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [00:38<00:57,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12: t_curr = 823.5294189453125, t_prev = 842.5925903320312\n",
      "t:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [00:41<00:54,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13: t_curr = 842.5925903320312, t_prev = 859.6491088867188\n",
      "t:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [00:44<00:51,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14: t_curr = 859.6491088867188, t_prev = 875.0\n",
      "t:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [00:48<00:47,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: t_curr = 875.0, t_prev = 888.888916015625\n",
      "t:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [00:51<00:44,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16: t_curr = 888.888916015625, t_prev = 901.51513671875\n",
      "t:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [00:54<00:41,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17: t_curr = 901.51513671875, t_prev = 913.04345703125\n",
      "t:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [00:57<00:38,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18: t_curr = 913.04345703125, t_prev = 923.611083984375\n",
      "t:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [01:00<00:35,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19: t_curr = 923.611083984375, t_prev = 933.333251953125\n",
      "t:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [01:04<00:31,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: t_curr = 933.333251953125, t_prev = 942.3078002929688\n",
      "t:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [01:07<00:28,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21: t_curr = 942.3078002929688, t_prev = 950.6172485351562\n",
      "t:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [01:10<00:25,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22: t_curr = 950.6172485351562, t_prev = 958.3333740234375\n",
      "t:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [01:13<00:22,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23: t_curr = 958.3333740234375, t_prev = 965.5172119140625\n",
      "t:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [01:16<00:19,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24: t_curr = 965.5172119140625, t_prev = 972.22216796875\n",
      "t:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [01:20<00:16,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25: t_curr = 972.22216796875, t_prev = 978.49462890625\n",
      "t:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [01:24<00:14,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26: t_curr = 978.49462890625, t_prev = 984.375\n",
      "t:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [01:29<00:11,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27: t_curr = 984.375, t_prev = 989.8989868164062\n",
      "t:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [01:33<00:07,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28: t_curr = 989.8989868164062, t_prev = 995.0980834960938\n",
      "t:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [01:37<00:04,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29: t_curr = 995.0980834960938, t_prev = 1000.0\n",
      "t:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [01:42<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "sigmas: tensor([1.0000, 0.9951, 0.9899, 0.9844, 0.9785, 0.9722, 0.9655, 0.9583, 0.9506,\n",
      "        0.9423, 0.9333, 0.9236, 0.9130, 0.9015, 0.8889, 0.8750, 0.8596, 0.8426,\n",
      "        0.8235, 0.8021, 0.7778, 0.7500, 0.7179, 0.6806, 0.6364, 0.5833, 0.5185,\n",
      "        0.4375, 0.3333, 0.1944, 0.0000])\n",
      "Using inversed latents\n",
      "Step 0: t = 1000.0\n",
      "Step 1: t = 995.0980834960938\n",
      "Step 2: t = 989.8989868164062\n",
      "Step 3: t = 984.375\n",
      "Step 4: t = 978.49462890625\n",
      "Step 5: t = 972.22216796875\n",
      "Step 6: t = 965.5172119140625\n",
      "Step 7: t = 958.3333740234375\n",
      "Step 8: t = 950.6172485351562\n",
      "Step 9: t = 942.3078002929688\n",
      "Step 10: t = 933.333251953125\n",
      "Step 11: t = 923.611083984375\n",
      "Step 12: t = 913.04345703125\n",
      "Step 13: t = 901.51513671875\n",
      "Step 14: t = 888.888916015625\n",
      "Step 15: t = 875.0\n",
      "Step 16: t = 859.6491088867188\n",
      "Step 17: t = 842.5925903320312\n",
      "Step 18: t = 823.5294189453125\n",
      "Step 19: t = 802.0833129882812\n",
      "Step 20: t = 777.77783203125\n",
      "Step 21: t = 750.0\n",
      "Step 22: t = 717.94873046875\n",
      "Step 23: t = 680.5556030273438\n",
      "Step 24: t = 636.3637084960938\n",
      "Step 25: t = 583.3333740234375\n",
      "Step 26: t = 518.5184936523438\n",
      "Step 27: t = 437.5000305175781\n",
      "Step 28: t = 333.3333435058594\n",
      "Step 29: t = 194.44444274902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: t_curr = 1000.0, t_prev = 995.0980834960938\n",
      "t:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:03<01:39,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: t_curr = 995.0980834960938, t_prev = 989.8989868164062\n",
      "t:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:07<01:38,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: t_curr = 989.8989868164062, t_prev = 984.375\n",
      "t:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:10<01:35,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: t_curr = 984.375, t_prev = 978.49462890625\n",
      "t:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:14<01:32,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: t_curr = 978.49462890625, t_prev = 972.22216796875\n",
      "t:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:17<01:28,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: t_curr = 972.22216796875, t_prev = 965.5172119140625\n",
      "t:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:20<01:22,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: t_curr = 965.5172119140625, t_prev = 958.3333740234375\n",
      "t:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:24<01:17,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: t_curr = 958.3333740234375, t_prev = 950.6172485351562\n",
      "t:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:27<01:13,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: t_curr = 950.6172485351562, t_prev = 942.3078002929688\n",
      "t:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [00:30<01:09,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: t_curr = 942.3078002929688, t_prev = 933.333251953125\n",
      "t:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [00:33<01:05,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: t_curr = 933.333251953125, t_prev = 923.611083984375\n",
      "t:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [00:37<01:01,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11: t_curr = 923.611083984375, t_prev = 913.04345703125\n",
      "t:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [00:40<00:58,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12: t_curr = 913.04345703125, t_prev = 901.51513671875\n",
      "t:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [00:43<00:54,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13: t_curr = 901.51513671875, t_prev = 888.888916015625\n",
      "t:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [00:46<00:51,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14: t_curr = 888.888916015625, t_prev = 875.0\n",
      "t:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [00:49<00:48,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: t_curr = 875.0, t_prev = 859.6491088867188\n",
      "t:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [00:53<00:45,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16: t_curr = 859.6491088867188, t_prev = 842.5925903320312\n",
      "t:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [00:56<00:41,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17: t_curr = 842.5925903320312, t_prev = 823.5294189453125\n",
      "t:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [00:59<00:38,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18: t_curr = 823.5294189453125, t_prev = 802.0833129882812\n",
      "t:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [01:02<00:35,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19: t_curr = 802.0833129882812, t_prev = 777.77783203125\n",
      "t:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [01:05<00:32,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: t_curr = 777.77783203125, t_prev = 750.0\n",
      "t:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [01:09<00:28,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21: t_curr = 750.0, t_prev = 717.94873046875\n",
      "t:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [01:12<00:25,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22: t_curr = 717.94873046875, t_prev = 680.5556030273438\n",
      "t:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [01:15<00:22,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23: t_curr = 680.5556030273438, t_prev = 636.3637084960938\n",
      "t:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [01:18<00:19,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24: t_curr = 636.3637084960938, t_prev = 583.3333740234375\n",
      "t:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [01:21<00:16,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25: t_curr = 583.3333740234375, t_prev = 518.5184936523438\n",
      "t:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [01:25<00:12,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26: t_curr = 518.5184936523438, t_prev = 437.5000305175781\n",
      "t:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [01:28<00:09,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27: t_curr = 437.5000305175781, t_prev = 333.3333435058594\n",
      "t:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [01:31<00:06,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28: t_curr = 333.3333435058594, t_prev = 194.44444274902344\n",
      "t:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [01:34<00:03,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29: t_curr = 194.44444274902344, t_prev = 0.0\n",
      "t:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [01:37<00:00,  3.27s/it]\n",
      "\u001b[32m2025-04-03 12:50:22.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m709\u001b[0m - \u001b[1mSuccess, time: 235.00394535064697\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[32m2025-04-03 12:50:25.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mSample save to: ./results/rf-solver_2order/2025-04-03-12:50:22_seed42_a grey car navigates a curvy road surrounded by green grass trees and mountains..mp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run edit_video.py \\\n",
    "    --dit-weight \"/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt\" \\\n",
    "    --video-size 512 512 \\\n",
    "    --video-length 25 \\\n",
    "    --infer-steps 30 \\\n",
    "    --prompt \"a grey car navigates a curvy road surrounded by green grass trees and mountains.\" \\\n",
    "    --target-prompt \"a red sports-car navigates a curvy road surrounded by green grass trees and mountains.\" \\\n",
    "    --inject 5 \\\n",
    "    --seed 42 \\\n",
    "    --embedded-cfg-scale 2 \\\n",
    "    --flow-shift 7.0 \\\n",
    "    --flow-reverse \\\n",
    "    --use-cpu-offload \\\n",
    "    --use-fp8 \\\n",
    "    --save-path ./results/rf-solver_2order \\\n",
    "    --inverse-video-path \"/data/chx/V2VBench/videos/car-turn.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 12:50:25.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mGot text-to-video model root path: ckpts\u001b[0m\n",
      "\u001b[32m2025-04-03 12:50:25.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m190\u001b[0m - \u001b[1mBuilding model...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apply_final_norm': False,\n",
      " 'batch_size': 1,\n",
      " 'cfg_scale': 1.0,\n",
      " 'denoise_type': 'flow',\n",
      " 'disable_autocast': False,\n",
      " 'dit_weight': '/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt',\n",
      " 'embedded_cfg_scale': 2.0,\n",
      " 'feature_path': 'feature',\n",
      " 'flow_reverse': True,\n",
      " 'flow_shift': 7.0,\n",
      " 'flow_solver': 'euler',\n",
      " 'hidden_state_skip_layer': 2,\n",
      " 'infer_steps': 30,\n",
      " 'inject': 5,\n",
      " 'inverse_video_path': '/data/chx/BalanceCC-rename/Result/Animal/blackswan.mp4',\n",
      " 'latent_channels': 16,\n",
      " 'linear_schedule_end': 25,\n",
      " 'load_key': 'module',\n",
      " 'model': 'HYVideo-T/2-cfgdistill',\n",
      " 'model_base': 'ckpts',\n",
      " 'model_resolution': '540p',\n",
      " 'name_suffix': '',\n",
      " 'neg_prompt': None,\n",
      " 'num_videos': 1,\n",
      " 'precision': 'bf16',\n",
      " 'prompt': 'A black swan swimming in a pond with lush greenery in the '\n",
      "           'background.',\n",
      " 'prompt_template': 'dit-llm-encode',\n",
      " 'prompt_template_video': 'dit-llm-encode-video',\n",
      " 'reproduce': False,\n",
      " 'ring_degree': 1,\n",
      " 'rope_theta': 256,\n",
      " 'save_path': './results',\n",
      " 'save_path_suffix': '',\n",
      " 'seed': 42,\n",
      " 'seed_type': 'auto',\n",
      " 'target_prompt': 'A majestic flamingo swimming in a pond with lush greenery '\n",
      "                  'in the background.',\n",
      " 'text_encoder': 'llm',\n",
      " 'text_encoder_2': 'clipL',\n",
      " 'text_encoder_precision': 'fp16',\n",
      " 'text_encoder_precision_2': 'fp16',\n",
      " 'text_len': 256,\n",
      " 'text_len_2': 77,\n",
      " 'text_states_dim': 4096,\n",
      " 'text_states_dim_2': 768,\n",
      " 'tokenizer': 'llm',\n",
      " 'tokenizer_2': 'clipL',\n",
      " 'ulysses_degree': 1,\n",
      " 'use_cpu_offload': True,\n",
      " 'use_fp8': True,\n",
      " 'use_linear_quadratic_schedule': False,\n",
      " 'vae': '884-16c-hy',\n",
      " 'vae_precision': 'fp16',\n",
      " 'vae_tiling': True,\n",
      " 'video_length': 53,\n",
      " 'video_size': [512, 512]}\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 12:52:20.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mload_state_dict\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mLoading torch model /home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt...\u001b[0m\n",
      "\u001b[32m2025-04-03 12:53:03.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLoading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-t2v-720p/vae\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-03 12:53:06.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mVAE to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-04-03 12:53:06.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "Loading checkpoint shards: 100%|| 4/4 [00:42<00:00, 10.56s/it]\n",
      "\u001b[32m2025-04-03 12:53:54.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-04-03 12:53:54.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "\u001b[32m2025-04-03 12:53:55.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[32m2025-04-03 12:53:56.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-04-03 12:53:56.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable sequential CPU offload.\n",
      "Updated args:\n",
      "{'apply_final_norm': False,\n",
      " 'batch_size': 1,\n",
      " 'cfg_scale': 1.0,\n",
      " 'denoise_type': 'flow',\n",
      " 'disable_autocast': False,\n",
      " 'dit_weight': '/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt',\n",
      " 'embedded_cfg_scale': 2.0,\n",
      " 'feature_path': 'feature',\n",
      " 'flow_reverse': True,\n",
      " 'flow_shift': 7.0,\n",
      " 'flow_solver': 'euler',\n",
      " 'hidden_state_skip_layer': 2,\n",
      " 'infer_steps': 30,\n",
      " 'inject': 5,\n",
      " 'inverse_video_path': '/data/chx/BalanceCC-rename/Result/Animal/blackswan.mp4',\n",
      " 'latent_channels': 16,\n",
      " 'linear_schedule_end': 25,\n",
      " 'load_key': 'module',\n",
      " 'model': 'HYVideo-T/2-cfgdistill',\n",
      " 'model_base': 'ckpts',\n",
      " 'model_resolution': '540p',\n",
      " 'name_suffix': '',\n",
      " 'neg_prompt': None,\n",
      " 'num_videos': 1,\n",
      " 'precision': 'bf16',\n",
      " 'prompt': 'A black swan swimming in a pond with lush greenery in the '\n",
      "           'background.',\n",
      " 'prompt_template': 'dit-llm-encode',\n",
      " 'prompt_template_video': 'dit-llm-encode-video',\n",
      " 'reproduce': False,\n",
      " 'ring_degree': 1,\n",
      " 'rope_theta': 256,\n",
      " 'save_path': './results',\n",
      " 'save_path_suffix': '',\n",
      " 'seed': 42,\n",
      " 'seed_type': 'auto',\n",
      " 'target_prompt': 'A majestic flamingo swimming in a pond with lush greenery '\n",
      "                  'in the background.',\n",
      " 'text_encoder': 'llm',\n",
      " 'text_encoder_2': 'clipL',\n",
      " 'text_encoder_precision': 'fp16',\n",
      " 'text_encoder_precision_2': 'fp16',\n",
      " 'text_len': 256,\n",
      " 'text_len_2': 77,\n",
      " 'text_states_dim': 4096,\n",
      " 'text_states_dim_2': 768,\n",
      " 'tokenizer': 'llm',\n",
      " 'tokenizer_2': 'clipL',\n",
      " 'ulysses_degree': 1,\n",
      " 'use_cpu_offload': True,\n",
      " 'use_fp8': True,\n",
      " 'use_linear_quadratic_schedule': False,\n",
      " 'vae': '884-16c-hy',\n",
      " 'vae_precision': 'fp16',\n",
      " 'vae_tiling': True,\n",
      " 'video_length': 53,\n",
      " 'video_size': [512, 512]}\n",
      "FPS of the video: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[32m2025-04-03 12:53:57.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m605\u001b[0m - \u001b[1mInput (height, width, video_length) = (512, 512, 53)\u001b[0m\n",
      "\u001b[32m2025-04-03 12:53:57.435\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m665\u001b[0m - \u001b[34m\u001b[1m\n",
      "                        height: 512\n",
      "                         width: 512\n",
      "                  video_length: 53\n",
      "                        prompt: ['A black swan swimming in a pond with lush greenery in the background.']\n",
      "                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']\n",
      "                          seed: 42\n",
      "                   infer_steps: 30\n",
      "         num_videos_per_prompt: 1\n",
      "                guidance_scale: 1.0\n",
      "                      n_tokens: 14336\n",
      "                    flow_shift: 7.0\n",
      "       embedded_guidance_scale: 2.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "sigmas_reverse\n",
      "sigmas: tensor([0.0000, 0.1944, 0.3333, 0.4375, 0.5185, 0.5833, 0.6364, 0.6806, 0.7179,\n",
      "        0.7500, 0.7778, 0.8021, 0.8235, 0.8426, 0.8596, 0.8750, 0.8889, 0.9015,\n",
      "        0.9130, 0.9236, 0.9333, 0.9423, 0.9506, 0.9583, 0.9655, 0.9722, 0.9785,\n",
      "        0.9844, 0.9899, 0.9951, 1.0000])\n",
      "Using inversed latents\n",
      "Step 0: t = 0.0\n",
      "Step 1: t = 194.44444274902344\n",
      "Step 2: t = 333.3333435058594\n",
      "Step 3: t = 437.5000305175781\n",
      "Step 4: t = 518.5184936523438\n",
      "Step 5: t = 583.3333740234375\n",
      "Step 6: t = 636.3637084960938\n",
      "Step 7: t = 680.5556030273438\n",
      "Step 8: t = 717.94873046875\n",
      "Step 9: t = 750.0\n",
      "Step 10: t = 777.77783203125\n",
      "Step 11: t = 802.0833129882812\n",
      "Step 12: t = 823.5294189453125\n",
      "Step 13: t = 842.5925903320312\n",
      "Step 14: t = 859.6491088867188\n",
      "Step 15: t = 875.0\n",
      "Step 16: t = 888.888916015625\n",
      "Step 17: t = 901.51513671875\n",
      "Step 18: t = 913.04345703125\n",
      "Step 19: t = 923.611083984375\n",
      "Step 20: t = 933.333251953125\n",
      "Step 21: t = 942.3078002929688\n",
      "Step 22: t = 950.6172485351562\n",
      "Step 23: t = 958.3333740234375\n",
      "Step 24: t = 965.5172119140625\n",
      "Step 25: t = 972.22216796875\n",
      "Step 26: t = 978.49462890625\n",
      "Step 27: t = 984.375\n",
      "Step 28: t = 989.8989868164062\n",
      "Step 29: t = 995.0980834960938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: t_curr = 0.0, t_prev = 194.44444274902344\n",
      "t:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:06<03:17,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: t_curr = 194.44444274902344, t_prev = 333.3333435058594\n",
      "t:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:13<03:10,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: t_curr = 333.3333435058594, t_prev = 437.5000305175781\n",
      "t:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:20<03:04,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: t_curr = 437.5000305175781, t_prev = 518.5184936523438\n",
      "t:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:27<02:57,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: t_curr = 518.5184936523438, t_prev = 583.3333740234375\n",
      "t:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:34<02:50,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: t_curr = 583.3333740234375, t_prev = 636.3637084960938\n",
      "t:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:40<02:44,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: t_curr = 636.3637084960938, t_prev = 680.5556030273438\n",
      "t:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:47<02:37,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: t_curr = 680.5556030273438, t_prev = 717.94873046875\n",
      "t:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:54<02:30,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: t_curr = 717.94873046875, t_prev = 750.0\n",
      "t:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [01:01<02:24,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: t_curr = 750.0, t_prev = 777.77783203125\n",
      "t:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [01:08<02:17,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: t_curr = 777.77783203125, t_prev = 802.0833129882812\n",
      "t:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [01:15<02:11,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11: t_curr = 802.0833129882812, t_prev = 823.5294189453125\n",
      "t:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [01:22<02:04,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12: t_curr = 823.5294189453125, t_prev = 842.5925903320312\n",
      "t:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [01:29<01:57,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13: t_curr = 842.5925903320312, t_prev = 859.6491088867188\n",
      "t:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [01:36<01:50,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14: t_curr = 859.6491088867188, t_prev = 875.0\n",
      "t:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [01:43<01:43,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: t_curr = 875.0, t_prev = 888.888916015625\n",
      "t:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [01:50<01:36,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16: t_curr = 888.888916015625, t_prev = 901.51513671875\n",
      "t:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [01:56<01:30,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17: t_curr = 901.51513671875, t_prev = 913.04345703125\n",
      "t:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [02:03<01:23,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18: t_curr = 913.04345703125, t_prev = 923.611083984375\n",
      "t:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [02:10<01:16,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19: t_curr = 923.611083984375, t_prev = 933.333251953125\n",
      "t:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [02:17<01:09,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: t_curr = 933.333251953125, t_prev = 942.3078002929688\n",
      "t:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [02:24<01:02,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21: t_curr = 942.3078002929688, t_prev = 950.6172485351562\n",
      "t:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [02:31<00:54,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22: t_curr = 950.6172485351562, t_prev = 958.3333740234375\n",
      "t:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [02:38<00:48,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23: t_curr = 958.3333740234375, t_prev = 965.5172119140625\n",
      "t:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [02:45<00:41,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24: t_curr = 965.5172119140625, t_prev = 972.22216796875\n",
      "t:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [02:51<00:34,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25: t_curr = 972.22216796875, t_prev = 978.49462890625\n",
      "t:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [03:01<00:30,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26: t_curr = 978.49462890625, t_prev = 984.375\n",
      "t:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [03:09<00:23,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27: t_curr = 984.375, t_prev = 989.8989868164062\n",
      "t:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [03:18<00:16,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28: t_curr = 989.8989868164062, t_prev = 995.0980834960938\n",
      "t:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [03:27<00:08,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29: t_curr = 995.0980834960938, t_prev = 1000.0\n",
      "t:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [03:35<00:00,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "sigmas: tensor([1.0000, 0.9951, 0.9899, 0.9844, 0.9785, 0.9722, 0.9655, 0.9583, 0.9506,\n",
      "        0.9423, 0.9333, 0.9236, 0.9130, 0.9015, 0.8889, 0.8750, 0.8596, 0.8426,\n",
      "        0.8235, 0.8021, 0.7778, 0.7500, 0.7179, 0.6806, 0.6364, 0.5833, 0.5185,\n",
      "        0.4375, 0.3333, 0.1944, 0.0000])\n",
      "Using inversed latents\n",
      "Step 0: t = 1000.0\n",
      "Step 1: t = 995.0980834960938\n",
      "Step 2: t = 989.8989868164062\n",
      "Step 3: t = 984.375\n",
      "Step 4: t = 978.49462890625\n",
      "Step 5: t = 972.22216796875\n",
      "Step 6: t = 965.5172119140625\n",
      "Step 7: t = 958.3333740234375\n",
      "Step 8: t = 950.6172485351562\n",
      "Step 9: t = 942.3078002929688\n",
      "Step 10: t = 933.333251953125\n",
      "Step 11: t = 923.611083984375\n",
      "Step 12: t = 913.04345703125\n",
      "Step 13: t = 901.51513671875\n",
      "Step 14: t = 888.888916015625\n",
      "Step 15: t = 875.0\n",
      "Step 16: t = 859.6491088867188\n",
      "Step 17: t = 842.5925903320312\n",
      "Step 18: t = 823.5294189453125\n",
      "Step 19: t = 802.0833129882812\n",
      "Step 20: t = 777.77783203125\n",
      "Step 21: t = 750.0\n",
      "Step 22: t = 717.94873046875\n",
      "Step 23: t = 680.5556030273438\n",
      "Step 24: t = 636.3637084960938\n",
      "Step 25: t = 583.3333740234375\n",
      "Step 26: t = 518.5184936523438\n",
      "Step 27: t = 437.5000305175781\n",
      "Step 28: t = 333.3333435058594\n",
      "Step 29: t = 194.44444274902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: t_curr = 1000.0, t_prev = 995.0980834960938\n",
      "t:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1/30 [00:07<03:24,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: t_curr = 995.0980834960938, t_prev = 989.8989868164062\n",
      "t:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 2/30 [00:14<03:18,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: t_curr = 989.8989868164062, t_prev = 984.375\n",
      "t:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 3/30 [00:21<03:11,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: t_curr = 984.375, t_prev = 978.49462890625\n",
      "t:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 4/30 [00:28<03:05,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: t_curr = 978.49462890625, t_prev = 972.22216796875\n",
      "t:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 5/30 [00:35<02:59,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: t_curr = 972.22216796875, t_prev = 965.5172119140625\n",
      "t:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 6/30 [00:42<02:49,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: t_curr = 965.5172119140625, t_prev = 958.3333740234375\n",
      "t:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 7/30 [00:49<02:40,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: t_curr = 958.3333740234375, t_prev = 950.6172485351562\n",
      "t:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 8/30 [00:56<02:32,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: t_curr = 950.6172485351562, t_prev = 942.3078002929688\n",
      "t:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 9/30 [01:03<02:25,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: t_curr = 942.3078002929688, t_prev = 933.333251953125\n",
      "t:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 10/30 [01:09<02:17,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: t_curr = 933.333251953125, t_prev = 923.611083984375\n",
      "t:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 11/30 [01:16<02:10,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11: t_curr = 923.611083984375, t_prev = 913.04345703125\n",
      "t:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 12/30 [01:23<02:04,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12: t_curr = 913.04345703125, t_prev = 901.51513671875\n",
      "t:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 13/30 [01:30<01:57,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13: t_curr = 901.51513671875, t_prev = 888.888916015625\n",
      "t:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 14/30 [01:37<01:50,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14: t_curr = 888.888916015625, t_prev = 875.0\n",
      "t:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 15/30 [01:44<01:44,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: t_curr = 875.0, t_prev = 859.6491088867188\n",
      "t:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 16/30 [01:51<01:37,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16: t_curr = 859.6491088867188, t_prev = 842.5925903320312\n",
      "t:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 17/30 [01:58<01:29,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17: t_curr = 842.5925903320312, t_prev = 823.5294189453125\n",
      "t:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 18/30 [02:05<01:22,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18: t_curr = 823.5294189453125, t_prev = 802.0833129882812\n",
      "t:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 19/30 [02:12<01:15,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19: t_curr = 802.0833129882812, t_prev = 777.77783203125\n",
      "t:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 20/30 [02:18<01:08,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: t_curr = 777.77783203125, t_prev = 750.0\n",
      "t:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 21/30 [02:25<01:01,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21: t_curr = 750.0, t_prev = 717.94873046875\n",
      "t:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 22/30 [02:32<00:54,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 22: t_curr = 717.94873046875, t_prev = 680.5556030273438\n",
      "t:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 23/30 [02:39<00:48,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 23: t_curr = 680.5556030273438, t_prev = 636.3637084960938\n",
      "t:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 24/30 [02:46<00:41,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 24: t_curr = 636.3637084960938, t_prev = 583.3333740234375\n",
      "t:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 25/30 [02:53<00:34,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25: t_curr = 583.3333740234375, t_prev = 518.5184936523438\n",
      "t:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 26/30 [03:00<00:27,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26: t_curr = 518.5184936523438, t_prev = 437.5000305175781\n",
      "t:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 27/30 [03:06<00:20,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 27: t_curr = 437.5000305175781, t_prev = 333.3333435058594\n",
      "t:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 28/30 [03:13<00:13,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 28: t_curr = 333.3333435058594, t_prev = 194.44444274902344\n",
      "t:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 29/30 [03:20<00:06,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 29: t_curr = 194.44444274902344, t_prev = 0.0\n",
      "t:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [03:27<00:00,  6.92s/it]\n",
      "\u001b[32m2025-04-03 13:01:46.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m709\u001b[0m - \u001b[1mSuccess, time: 469.08821153640747\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[32m2025-04-03 13:01:49.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mSample save to: ./results/2025-04-03-13:01:46_seed42_A black swan swimming in a pond with lush greenery in the background..mp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run edit_video.py \\\n",
    "    --dit-weight \"/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt\" \\\n",
    "    --video-size 512 512 \\\n",
    "    --video-length 53 \\\n",
    "    --infer-steps 30 \\\n",
    "    --prompt \"A black swan swimming in a pond with lush greenery in the background.\" \\\n",
    "    --target-prompt \"A majestic flamingo swimming in a pond with lush greenery in the background.\" \\\n",
    "    --inject 5 \\\n",
    "    --seed 42 \\\n",
    "    --embedded-cfg-scale 2 \\\n",
    "    --flow-shift 7.0 \\\n",
    "    --flow-reverse \\\n",
    "    --use-cpu-offload \\\n",
    "    --use-fp8 \\\n",
    "    --save-path ./results \\\n",
    "    --inverse-video-path \"/data/chx/BalanceCC-rename/Result/Animal/blackswan.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chx/anaconda3/envs/HunyuanVideo-std/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-01-14 20:33:19.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1mGot text-to-video model root path: ckpts\u001b[0m\n",
      "\u001b[32m2025-01-14 20:33:19.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mBuilding model...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect you are not use the latest yunchang. Please install yunchang>=0.4.0\n",
      "Namespace(model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='ckpts', dit_weight='/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt', model_resolution='540p', load_key='module', use_cpu_offload=True, batch_size=1, infer_steps=30, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[512, 512], video_length=25, prompt='A cat walks on the grass, realistic style.', seed_type='auto', seed=42, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, use_fp8=True, reproduce=False, ulysses_degree=1, ring_degree=1, inverse_video_path='/home/chx/mySrc/HunyuanVideo', target_prompt=None)\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chx/mySrc/HunyuanVideo/hyvideo/modules/fp8_optimization.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fp8_map = torch.load(fp8_map_path, map_location=lambda storage, loc: storage)\n",
      "\u001b[32m2025-01-14 20:35:44.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mload_state_dict\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mLoading torch model /home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt...\u001b[0m\n",
      "/home/chx/mySrc/HunyuanVideo/hyvideo/inference.py:345: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
      "\u001b[32m2025-01-14 20:35:58.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLoading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-t2v-720p/vae\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chx/mySrc/HunyuanVideo/hyvideo/vae/__init__.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(vae_ckpt, map_location=vae.device)\n",
      "\u001b[32m2025-01-14 20:36:02.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mVAE to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-01-14 20:36:02.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "Loading checkpoint shards: 100%|| 4/4 [00:05<00:00,  1.36s/it]\n",
      "\u001b[32m2025-01-14 20:36:13.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-01-14 20:36:13.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "\u001b[32m2025-01-14 20:36:13.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[32m2025-01-14 20:36:14.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-01-14 20:36:14.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[32m2025-01-14 20:36:14.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m590\u001b[0m - \u001b[1mInput (height, width, video_length) = (512, 512, 25)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable sequential CPU offload.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-14 20:36:15.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m650\u001b[0m - \u001b[34m\u001b[1m\n",
      "                        height: 512\n",
      "                         width: 512\n",
      "                  video_length: 25\n",
      "                        prompt: ['A cat walks on the grass, realistic style.']\n",
      "                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']\n",
      "                          seed: 42\n",
      "                   infer_steps: 30\n",
      "         num_videos_per_prompt: 1\n",
      "                guidance_scale: 1.0\n",
      "                      n_tokens: 7168\n",
      "                    flow_shift: 7.0\n",
      "       embedded_guidance_scale: 6.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._execution_device cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "Step 0: t = 1000.0\n",
      "Step 1: t = 995.0980834960938\n",
      "Step 2: t = 989.8989868164062\n",
      "Step 3: t = 984.375\n",
      "Step 4: t = 978.49462890625\n",
      "Step 5: t = 972.22216796875\n",
      "Step 6: t = 965.5172119140625\n",
      "Step 7: t = 958.3333740234375\n",
      "Step 8: t = 950.6172485351562\n",
      "Step 9: t = 942.3078002929688\n",
      "Step 10: t = 933.333251953125\n",
      "Step 11: t = 923.611083984375\n",
      "Step 12: t = 913.04345703125\n",
      "Step 13: t = 901.51513671875\n",
      "Step 14: t = 888.888916015625\n",
      "Step 15: t = 875.0\n",
      "Step 16: t = 859.6491088867188\n",
      "Step 17: t = 842.5925903320312\n",
      "Step 18: t = 823.5294189453125\n",
      "Step 19: t = 802.0833129882812\n",
      "Step 20: t = 777.77783203125\n",
      "Step 21: t = 750.0\n",
      "Step 22: t = 717.94873046875\n",
      "Step 23: t = 680.5556030273438\n",
      "Step 24: t = 636.3637084960938\n",
      "Step 25: t = 583.3333740234375\n",
      "Step 26: t = 518.5184936523438\n",
      "Step 27: t = 437.5000305175781\n",
      "Step 28: t = 333.3333435058594\n",
      "Step 29: t = 194.44444274902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [00:49<00:00,  1.64s/it]\n",
      "\u001b[32m2025-01-14 20:37:23.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m684\u001b[0m - \u001b[1mSuccess, time: 67.84050464630127\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[32m2025-01-14 20:37:24.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mSample save to: ./results/2025-01-14-20:37:23_seed42_A cat walks on the grass, realistic style..mp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run sample_video.py \\\n",
    "    --dit-weight \"/home/chx/mySrc/HunyuanVideo/ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt\" \\\n",
    "    --video-size 512 512 \\\n",
    "    --video-length 25 \\\n",
    "    --infer-steps 30 \\\n",
    "    --prompt \"A cat walks on the grass, realistic style.\" \\\n",
    "    --seed 42 \\\n",
    "    --embedded-cfg-scale 6.0 \\\n",
    "    --flow-shift 7.0 \\\n",
    "    --flow-reverse \\\n",
    "    --use-cpu-offload \\\n",
    "    --use-fp8 \\\n",
    "    --save-path ./results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HunyuanVideo-std",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
